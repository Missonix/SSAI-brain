#!/usr/bin/env python3
"""
æ¸…ç†ç³»ç»Ÿé”™è¯¯æ¶ˆæ¯è„šæœ¬
åˆ é™¤å·²ç»é”™è¯¯å­˜å‚¨åœ¨è§’è‰²å†å²èŠå¤©è®°å½•ä¸­çš„ç³»ç»Ÿé”™è¯¯æ¶ˆæ¯
"""

import asyncio
import logging
import json
import sys
import os
import redis.asyncio as redis

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), 'mcp_agent'))

from mcp_agent.database_config import get_mysql_session, get_redis_client

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# éœ€è¦æ¸…ç†çš„ç³»ç»Ÿé”™è¯¯æ¶ˆæ¯æ¨¡å¼
SYSTEM_ERROR_PATTERNS = [
    "æœåŠ¡å™¨æš‚æ—¶æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ï¼Œè¯·ç¨åå†è¯•",
    "AIæœåŠ¡æš‚æ—¶æœ‰ç‚¹é—®é¢˜",
    "Google AIæœåŠ¡å‡ºç°äº†ä¸€äº›é—®é¢˜",
    "é‡åˆ°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜",
    "âš ï¸ åœ°ç†ä½ç½®é™åˆ¶",
    "âš ï¸ ç½‘ç»œè¿æ¥é”™è¯¯", 
    "âš ï¸ å“åº”è¶…æ—¶",
    "âš ï¸ APIæœåŠ¡é”™è¯¯",
    "âš ï¸ Google AIæœåŠ¡é”™è¯¯",
    "âš ï¸ ç³»ç»Ÿé”™è¯¯",
    "ç½‘ç»œè¿æ¥å¥½åƒæœ‰ç‚¹é—®é¢˜",
    "å“åº”æœ‰ç‚¹æ…¢ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜",
    "AIæœåŠ¡æš‚æ—¶æœ‰ç‚¹é—®é¢˜ï¼Œå¯èƒ½æ˜¯é…é¢é™åˆ¶",
    "å“ˆå“ˆï¼Œçœ‹èµ·æ¥æˆ‘è¿™è¾¹çš„AIæœåŠ¡æœ‰ç‚¹åœ°ç†ä½ç½®é™åˆ¶çš„é—®é¢˜"
]

async def cleanup_mysql_messages():
    """æ¸…ç†MySQLä¸­çš„ç³»ç»Ÿé”™è¯¯æ¶ˆæ¯"""
    logger.info("ğŸ”„ å¼€å§‹æ¸…ç†MySQLä¸­çš„ç³»ç»Ÿé”™è¯¯æ¶ˆæ¯...")
    
    try:
        from sqlalchemy import text
        deleted_count = 0
        
        async with get_mysql_session() as session:
            # éå†æ¯ä¸ªé”™è¯¯æ¨¡å¼
            for pattern in SYSTEM_ERROR_PATTERNS:
                # æŸ¥æ‰¾åŒ¹é…çš„æ¶ˆæ¯
                query = text("""
                    SELECT message_id, session_id, message_content 
                    FROM conversation_messages 
                    WHERE sender_type = 'agent' 
                    AND message_content LIKE :pattern
                """)
                
                result = await session.execute(query, {"pattern": f"%{pattern}%"})
                messages = result.fetchall()
                
                if messages:
                    logger.info(f"å‘ç° {len(messages)} æ¡åŒ…å«æ¨¡å¼ '{pattern}' çš„æ¶ˆæ¯")
                    
                    # åˆ é™¤è¿™äº›æ¶ˆæ¯
                    for message in messages:
                        message_id, session_id, content = message
                        
                        delete_query = text("DELETE FROM conversation_messages WHERE message_id = :message_id")
                        await session.execute(delete_query, {"message_id": message_id})
                        
                        logger.info(f"åˆ é™¤æ¶ˆæ¯ {message_id}: {content[:50]}...")
                        deleted_count += 1
            
            # æäº¤äº‹åŠ¡
            await session.commit()
        
        logger.info(f"âœ… MySQLæ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {deleted_count} æ¡ç³»ç»Ÿé”™è¯¯æ¶ˆæ¯")
        return deleted_count
        
    except Exception as e:
        logger.error(f"âŒ MySQLæ¸…ç†å¤±è´¥: {e}")
        return 0

async def cleanup_redis_messages():
    """æ¸…ç†Redisä¸­çš„ç³»ç»Ÿé”™è¯¯æ¶ˆæ¯"""
    logger.info("ğŸ”„ å¼€å§‹æ¸…ç†Redisä¸­çš„ç³»ç»Ÿé”™è¯¯æ¶ˆæ¯...")
    
    try:
        redis_client = await get_redis_client()
        
        # è·å–æ‰€æœ‰sessioné”®
        session_keys = await redis_client.keys("session:*:messages")
        deleted_count = 0
        
        for session_key in session_keys:
            try:
                # è·å–è¯¥sessionçš„æ‰€æœ‰æ¶ˆæ¯
                messages = await redis_client.lrange(session_key, 0, -1)
                
                new_messages = []
                for msg_data in messages:
                    try:
                        # è§£ææ¶ˆæ¯
                        if isinstance(msg_data, bytes):
                            msg_str = msg_data.decode('utf-8')
                        else:
                            msg_str = str(msg_data)
                        
                        msg = json.loads(msg_str)
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ç³»ç»Ÿé”™è¯¯æ¶ˆæ¯
                        is_system_error = False
                        if msg.get('sender_type') == 'agent':
                            content = msg.get('message_content', '')
                            for pattern in SYSTEM_ERROR_PATTERNS:
                                if pattern in content:
                                    logger.info(f"åˆ é™¤Redisæ¶ˆæ¯: {content[:50]}...")
                                    is_system_error = True
                                    deleted_count += 1
                        
                        # å¦‚æœä¸æ˜¯ç³»ç»Ÿé”™è¯¯æ¶ˆæ¯ï¼Œä¿ç•™
                        if not is_system_error:
                            new_messages.append(msg_data)
                    
                    except (json.JSONDecodeError, Exception) as e:
                        logger.warning(f"è§£ææ¶ˆæ¯å¤±è´¥ï¼Œä¿ç•™åŸæ¶ˆæ¯: {e}")
                        new_messages.append(msg_data)
                
                # å¦‚æœæœ‰å˜åŒ–ï¼Œæ›´æ–°Redis
                if len(new_messages) < len(messages):
                    # æ¸…ç©ºåŸåˆ—è¡¨
                    await redis_client.delete(session_key)
                    
                    # é‡æ–°æ·»åŠ æ¸…ç†åçš„æ¶ˆæ¯
                    if new_messages:
                        await redis_client.rpush(session_key, *new_messages)
                        # é‡æ–°è®¾ç½®è¿‡æœŸæ—¶é—´
                        await redis_client.expire(session_key, 86400)
                    
                    logger.info(f"ä¼šè¯ {session_key} æ¸…ç†å®Œæˆ: {len(messages)} -> {len(new_messages)}")
            
            except Exception as e:
                logger.warning(f"å¤„ç†ä¼šè¯ {session_key} å¤±è´¥: {e}")
                continue
        
        logger.info(f"âœ… Redisæ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {deleted_count} æ¡ç³»ç»Ÿé”™è¯¯æ¶ˆæ¯")
        return deleted_count
        
    except Exception as e:
        logger.error(f"âŒ Redisæ¸…ç†å¤±è´¥: {e}")
        return 0

async def cleanup_inner_os_leak_messages():
    """æ¸…ç†Redisä¸­åŒ…å«å†…å¿ƒOSæ³„éœ²çš„æ¶ˆæ¯"""
    try:
        redis_client = await get_redis_client()
        
        # è·å–æ‰€æœ‰ä¼šè¯é”®
        session_keys = await redis_client.keys("session:*:messages")
        
        cleaned_count = 0
        total_sessions = len(session_keys)
        
        print(f"ğŸ” å¼€å§‹æ£€æŸ¥ {total_sessions} ä¸ªä¼šè¯çš„æ¶ˆæ¯...")
        
        for session_key in session_keys:
            session_id = session_key.decode('utf-8').split(':')[1] if isinstance(session_key, bytes) else session_key.split(':')[1]
            
            # è·å–ä¼šè¯ä¸­çš„æ‰€æœ‰æ¶ˆæ¯
            messages = await redis_client.lrange(session_key, 0, -1)
            
            for i, msg_json in enumerate(messages):
                try:
                    if isinstance(msg_json, bytes):
                        msg_str = msg_json.decode('utf-8')
                    else:
                        msg_str = str(msg_json)
                    
                    msg = json.loads(msg_str)
                    message_content = msg.get('message_content', '')
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å†…å¿ƒOSæ³„éœ²çš„æ¨¡å¼
                    leak_patterns = [
                        "ï¼ˆç¨å¾®", "ï¼ˆè§£é‡Š", "ï¼ˆæƒ³æƒ³", "ï¼ˆä¸è¦é€éœ²", "ï¼ˆæ‰¾ä¸ªç†ç”±", "ï¼ˆæ€åº¦è¦",
                        "ï¼ˆç„¶å", "ï¼ˆä½†ä¸è¦", "ï¼ˆç­–ç•¥", "ï¼ˆè®¡åˆ’", "ï¼ˆå†…å¿ƒOSï¼š", "å†…å¿ƒOSï¼š",
                        "ï¼ˆå†…å¿ƒæƒ³æ³•ï¼š", "å†…å¿ƒæƒ³æ³•ï¼š", "ï¼ˆå¿ƒé‡Œæƒ³ï¼š", "å¿ƒé‡Œæƒ³ï¼š"
                    ]
                    
                    has_leak = any(pattern in message_content for pattern in leak_patterns)
                    
                    if has_leak:
                        print(f"ğŸš¨ å‘ç°é—®é¢˜æ¶ˆæ¯åœ¨ä¼šè¯ {session_id}:")
                        print(f"   å†…å®¹: {message_content[:100]}...")
                        
                        # åˆ é™¤è¿™æ¡æ¶ˆæ¯
                        await redis_client.lrem(session_key, 1, msg_json)
                        cleaned_count += 1
                        print(f"   âœ… å·²åˆ é™¤")
                
                except json.JSONDecodeError:
                    print(f"âš ï¸ è·³è¿‡æ— æ•ˆJSONæ¶ˆæ¯: {msg_json[:50]}...")
                except Exception as e:
                    print(f"âŒ å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
        
        print(f"\nğŸ‰ æ¸…ç†å®Œæˆï¼")
        print(f"ğŸ“Š æ¸…ç†ç»Ÿè®¡:")
        print(f"   - æ£€æŸ¥çš„ä¼šè¯æ•°: {total_sessions}")
        print(f"   - åˆ é™¤çš„é—®é¢˜æ¶ˆæ¯æ•°: {cleaned_count}")
        
        await redis_client.close()
        
    except Exception as e:
        print(f"âŒ æ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")

async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†ç³»ç»Ÿé”™è¯¯æ¶ˆæ¯...")
    
    # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
    from mcp_agent.database_config import init_all_databases
    await init_all_databases()
    
    # æ¸…ç†MySQL
    mysql_count = await cleanup_mysql_messages()
    
    # æ¸…ç†Redis  
    redis_count = await cleanup_redis_messages()
    
    # æ¸…ç†åŒ…å«å†…å¿ƒOSæ³„éœ²çš„Redisæ¶ˆæ¯
    await cleanup_inner_os_leak_messages()
    
    # å…³é—­æ•°æ®åº“è¿æ¥
    from mcp_agent.database_config import close_all_databases
    await close_all_databases()
    
    logger.info(f"ğŸ‰ æ¸…ç†å®Œæˆï¼")
    logger.info(f"   MySQL: åˆ é™¤ {mysql_count} æ¡æ¶ˆæ¯")
    logger.info(f"   Redis: åˆ é™¤ {redis_count} æ¡æ¶ˆæ¯")
    logger.info(f"   æ€»è®¡: åˆ é™¤ {mysql_count + redis_count} æ¡ç³»ç»Ÿé”™è¯¯æ¶ˆæ¯")

if __name__ == "__main__":
    asyncio.run(main()) 