# ç»Ÿä¸€æ¨¡å‹é…ç½®ç®¡ç†å™¨

æœ¬é¡¹ç›®ä½¿ç”¨ç»Ÿä¸€çš„æ¨¡å‹é…ç½®ç®¡ç†å™¨æ¥ç®¡ç†æ‰€æœ‰LLMæ¨¡å‹çš„é…ç½®ï¼ŒåŒ…æ‹¬APIå¯†é’¥ã€æ¨¡å‹åç§°ã€base URLç­‰å‚æ•°ã€‚

## ğŸ¯ ä¸»è¦ç‰¹æ€§

- **ç»Ÿä¸€é…ç½®ç®¡ç†**: æ‰€æœ‰æ¨¡å‹é…ç½®é›†ä¸­åœ¨ä¸€ä¸ªåœ°æ–¹ç®¡ç†
- **å¤šæä¾›å•†æ”¯æŒ**: æ”¯æŒGeminiã€OpenAIã€Claudeã€Qwenã€GLMç­‰å¤šä¸ªæ¨¡å‹æä¾›å•†
- **ç¯å¢ƒå˜é‡è¦†ç›–**: æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡åŠ¨æ€é…ç½®
- **è‡ªåŠ¨ç¯å¢ƒè®¾ç½®**: è‡ªåŠ¨è®¾ç½®å¯¹åº”çš„ç¯å¢ƒå˜é‡
- **ç±»å‹å®‰å…¨**: ä½¿ç”¨TypeScripté£æ ¼çš„ç±»å‹æç¤º

## ğŸ“ æ–‡ä»¶ç»“æ„

```
mcp_agent/
â”œâ”€â”€ model_config.py              # ç»Ÿä¸€æ¨¡å‹é…ç½®ç®¡ç†å™¨
â”œâ”€â”€ model_config_example.py      # ä½¿ç”¨ç¤ºä¾‹
â””â”€â”€ MODEL_CONFIG_README.md       # æœ¬æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åŸºæœ¬ä½¿ç”¨

```python
from model_config import get_langchain_llm, get_genai_model, get_model_config

# è·å–å½“å‰é…ç½®
config = get_model_config()
print(f"å½“å‰ä½¿ç”¨: {config.provider.value} - {config.model_name}")

# è·å–LangChain LLMå®ä¾‹
llm = get_langchain_llm()

# è·å–Google GenerativeAIæ¨¡å‹å®ä¾‹
model = get_genai_model()
```

### 2. é…ç½®åˆ‡æ¢

```python
from model_config import switch_model, update_model_config

# åˆ‡æ¢åˆ°ä¸åŒçš„æ¨¡å‹
switch_model("openai", "gpt-4")           # åˆ‡æ¢åˆ°OpenAI GPT-4
switch_model("gemini", "gemini-1.5-pro") # åˆ‡æ¢åˆ°Gemini 1.5 Pro

# æ›´æ–°é…ç½®å‚æ•°
update_model_config(temperature=0.5, max_tokens=2000)
```

## âš™ï¸ é…ç½®æ–¹å¼

### 1. é»˜è®¤é…ç½®

é»˜è®¤ä½¿ç”¨Gemini 2.0 Flashæ¨¡å‹ï¼š

```python
DEFAULT_CONFIG = {
    "provider": ModelProvider.GEMINI,
    "model_name": "gemini-2.0-flash-exp",
    "api_key": "",
    "temperature": 0.0,
    "timeout": 30
}
```

### 2. ç¯å¢ƒå˜é‡é…ç½®

å¯ä»¥é€šè¿‡ä»¥ä¸‹ç¯å¢ƒå˜é‡è¦†ç›–é»˜è®¤é…ç½®ï¼š

```bash
# æ¨¡å‹æä¾›å•†å’Œåç§°
export MODEL_PROVIDER=gemini
export MODEL_NAME=gemini-2.0-flash-exp

# APIå¯†é’¥ï¼ˆæ ¹æ®æä¾›å•†é€‰æ‹©å¯¹åº”çš„ç¯å¢ƒå˜é‡ï¼‰
export GOOGLE_API_KEY=your_google_api_key
export OPENAI_API_KEY=your_openai_api_key
export ANTHROPIC_API_KEY=your_claude_api_key
export DASHSCOPE_API_KEY=your_qwen_api_key
export GLM_API_KEY=your_glm_api_key

# å…¶ä»–å‚æ•°
export MODEL_TEMPERATURE=0.0
export MODEL_MAX_TOKENS=2000
export MODEL_TIMEOUT=30
export MODEL_BASE_URL=https://api.openai.com/v1
```

### 3. ä»£ç ä¸­åŠ¨æ€é…ç½®

```python
from model_config import model_manager

# æ›´æ–°é…ç½®
model_manager.update_config(
    provider="openai",
    model_name="gpt-4",
    api_key="your_api_key",
    temperature=0.7
)
```

## ğŸ”§ æ”¯æŒçš„æ¨¡å‹æä¾›å•†

### Gemini (Google)
```python
switch_model("gemini", "gemini-2.0-flash-exp")
switch_model("gemini", "gemini-1.5-pro")
```

### OpenAI
```python
switch_model("openai", "gpt-4")
switch_model("openai", "gpt-3.5-turbo")
```

### Qwen (é˜¿é‡Œäº‘)
```python
switch_model("qwen", "qwen-turbo")
```

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### åœ¨é¡¹ç›®ä¸­ä½¿ç”¨

```python
# chat_agent.py
from model_config import get_langchain_llm, get_model_config

class EnhancedMCPAgent:
    def __init__(self, role_id: str = None):
        # ä½¿ç”¨ç»Ÿä¸€çš„æ¨¡å‹é…ç½®
        self.llm = get_langchain_llm()
        
        # è®°å½•å½“å‰ä½¿ç”¨çš„æ¨¡å‹é…ç½®
        model_config = get_model_config()
        self.logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_config.provider.value} - {model_config.model_name}")
```

```python
# thought_chain_generator.py
from model_config import get_genai_model, get_model_config

class ThoughtChainPromptGenerator:
    def __init__(self):
        # ä½¿ç”¨ç»Ÿä¸€çš„æ¨¡å‹é…ç½®
        self.model = get_genai_model()
        model_config = get_model_config()
        self.logger.info(f"âœ… ä½¿ç”¨æ¨¡å‹: {model_config.model_name}")
```

### è¿è¡Œç¤ºä¾‹

```bash
cd mcp_agent
python model_config_example.py
```

## ğŸ”„ è¿ç§»æŒ‡å—

### ä»ç¡¬ç¼–ç é…ç½®è¿ç§»

**ä¹‹å‰çš„ä»£ç :**
```python
# ç¡¬ç¼–ç APIå¯†é’¥å’Œæ¨¡å‹
api_key = ""
genai.configure(api_key=api_key)
model = genai.GenerativeModel('gemini-2.0-flash-exp')

llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash-exp",
    google_api_key=api_key,
    temperature=0.0
)
```

**è¿ç§»åçš„ä»£ç :**
```python
# ä½¿ç”¨ç»Ÿä¸€é…ç½®
from model_config import get_genai_model, get_langchain_llm

model = get_genai_model()
llm = get_langchain_llm()
```

### æ„é€ å‡½æ•°å‚æ•°è¿ç§»

**ä¹‹å‰:**
```python
def __init__(self, api_key: str, model_name: str = "gemini-2.0-flash-exp"):
    self.api_key = api_key
    genai.configure(api_key=api_key)
    self.model = genai.GenerativeModel(model_name)
```

**è¿ç§»å:**
```python
def __init__(self):
    self.model = get_genai_model()
    model_config = get_model_config()
    self.logger.info(f"âœ… ä½¿ç”¨æ¨¡å‹: {model_config.model_name}")
```

## ğŸ› ï¸ é«˜çº§åŠŸèƒ½

### 1. è·å–æä¾›å•†ä¿¡æ¯

```python
from model_config import model_manager

info = model_manager.get_provider_info()
print(f"æä¾›å•†: {info['provider']}")
print(f"æ¨¡å‹: {info['model_name']}")
print(f"æœ‰APIå¯†é’¥: {info['has_api_key']}")
```

### 2. è·å–ç‰¹å®šé…ç½®

```python
# è·å–LangChainé…ç½®
langchain_config = model_manager.get_langchain_config()

# è·å–GenAIé…ç½®
genai_config = model_manager.get_genai_config()
```

### 3. é¢„å®šä¹‰æ¨¡æ¿åˆ‡æ¢

```python
from model_config import ModelProvider

# ä½¿ç”¨é¢„å®šä¹‰æ¨¡æ¿
success = model_manager.switch_to_template(
    ModelProvider.OPENAI, 
    "gpt-4"
)
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **APIå¯†é’¥å®‰å…¨**: ä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç APIå¯†é’¥ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡
2. **æ¨¡å‹å…¼å®¹æ€§**: ç¡®ä¿åˆ‡æ¢æ¨¡å‹æ—¶APIå¯†é’¥æ­£ç¡®é…ç½®
3. **é”™è¯¯å¤„ç†**: æ¨¡å‹åˆå§‹åŒ–å¤±è´¥æ—¶ä¼šæŠ›å‡ºå¼‚å¸¸ï¼Œéœ€è¦é€‚å½“å¤„ç†
4. **ç¯å¢ƒå˜é‡ä¼˜å…ˆçº§**: ç¯å¢ƒå˜é‡ä¼šè¦†ç›–é»˜è®¤é…ç½®

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ¨¡å‹åˆå§‹åŒ–å¤±è´¥**
   ```
   âŒ ThoughtChainGeneratoråˆå§‹åŒ–å¤±è´¥: genaié…ç½®ä»…é€‚ç”¨äºGeminiæ¨¡å‹
   ```
   è§£å†³æ–¹æ¡ˆ: æ£€æŸ¥å½“å‰é…ç½®çš„æä¾›å•†æ˜¯å¦ä¸ä½¿ç”¨çš„æ¨¡å‹åŒ¹é…

2. **APIå¯†é’¥é”™è¯¯**
   ```
   âŒ APIå¯†é’¥æ— æ•ˆæˆ–æœªè®¾ç½®
   ```
   è§£å†³æ–¹æ¡ˆ: æ£€æŸ¥å¯¹åº”æä¾›å•†çš„ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®è®¾ç½®

3. **æ¨¡å‹ä¸æ”¯æŒ**
   ```
   âŒ æš‚ä¸æ”¯æŒçš„LangChainæä¾›å•†: xxx
   ```
   è§£å†³æ–¹æ¡ˆ: æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†æ”¯æŒçš„æ¨¡å‹æä¾›å•†

### è°ƒè¯•æ–¹æ³•

```python
from model_config import get_model_config

# æ£€æŸ¥å½“å‰é…ç½®
config = get_model_config()
print(f"æä¾›å•†: {config.provider}")
print(f"æ¨¡å‹: {config.model_name}")
print(f"APIå¯†é’¥: {config.api_key[:10]}..." if config.api_key else "æœªè®¾ç½®")
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [model_config.py](./model_config.py) - æ ¸å¿ƒé…ç½®ç®¡ç†å™¨
- [model_config_example.py](./model_config_example.py) - ä½¿ç”¨ç¤ºä¾‹
- [chat_agent.py](./chat_agent.py) - åœ¨èŠå¤©ä»£ç†ä¸­çš„ä½¿ç”¨
- [thought_chain_generator.py](../thought_chain_prompt_generator/thought_chain_generator.py) - åœ¨æ€ç»´é“¾ç”Ÿæˆå™¨ä¸­çš„ä½¿ç”¨ 